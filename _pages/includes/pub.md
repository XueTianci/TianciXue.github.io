
# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv preprint</div><img src='images/MEET.jpeg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Parameter-Efficient Tuning Helps Language Model Alignment](https://arxiv.org/pdf/2310.00819.pdf) \\
**Tianci Xue**, Ziqi Wang, Heng Ji

- **MEET**, a novel approach that incorporates parameter-efficient tuning to better optimize control tokens, thus benefitting controllable generation.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2021</div><img src='images/TADIS.jpeg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[TADIS: Steering Models for Deep-Thinking about Demonstration Examples](https://arxiv.org/pdf/2310.00901.pdf) \\
**Tianci Xue**, Ziqi Wang, Yixia Li, Yun Chen, Guanhua Chen

  - Steering LLMs for ``Deep-Thinking'' about demonstration examples instead of merely seeing, which alleviates the illusion of competence of models.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv preprint</div><img src='images/RCoT.jpeg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[RCOT: Detecting and Rectifying Factual Inconsistency in Reasoning by Reversing Chain-of-Thought](https://arxiv.org/pdf/2305.11499.pdf) \\
**Tianci Xue**, Ziqi Wang, Zhenhailong Wang, Chi Han, Pengfei Yu, Heng Ji

- **RCoT**, a novel method to improve LLMs' reasoning abilities by automatically detecting and rectifying factual inconsistency in LLMs‚Äô generated solutions.
</div>
</div>
