
# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL</div><img src='images/PACIT.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[PACIT: Unlocking the Power of Examples for Better In-Context Instruction Tuning](https://openreview.net/pdf?id=7uySifrWkjc) \\
**Tianci Xue**, Ziqi Wang, Yixia Li, Yun Chen, Guanhua Chen

  - PACIT: a simple and effective in-context instruction tuning method, first verifies the provided example's correctness, then uses this to generate a better response.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv preprint</div><img src='images/MEET.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Parameter-Efficient Tuning Helps Language Model Alignment](https://arxiv.org/pdf/2310.00819.pdf) \\
**Tianci Xue**, Ziqi Wang, Heng Ji

- **MEET**, a novel approach that incorporates parameter-efficient tuning to better optimize control tokens, thus benefitting controllable generation.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv preprint</div><img src='images/RCoT.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[RCOT: Detecting and Rectifying Factual Inconsistency in Reasoning by Reversing Chain-of-Thought](https://arxiv.org/pdf/2305.11499.pdf) \\
**Tianci Xue**, Ziqi Wang, Zhenhailong Wang, Chi Han, Pengfei Yu, Heng Ji

- **RCoT**, a novel method to improve LLMs' reasoning abilities by automatically detecting and rectifying factual inconsistency in LLMs‚Äô generated solutions.
</div>
</div>
